{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ResNet50 classification","metadata":{}},{"cell_type":"markdown","source":"### Import Libraries & Setup","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import models, transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nimport cv2\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##   Prepare Tumor Dataset for ResNet50\n### 1. Convert grayscale to 3 channels because ResNet50 expects 3-channel input.\n\n### 2. Resize to 224×224 for ResNet50.","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nimport cv2\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom torchvision import transforms\n\n# 1️⃣ Define Dataset\nclass TumorDataset(Dataset):\n    def __init__(self, img_paths, labels, transform=None):\n        self.img_paths = img_paths\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.img_paths)\n\n    def __getitem__(self, idx):\n        img_path = self.img_paths[idx]\n        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)  # ensure 3 channels\n        img = cv2.resize(img, (224,224))\n\n        if self.transform:\n            img = self.transform(img)\n\n        # Extra check: if somehow 1 channel remains, repeat it\n        if img.shape[0] == 1:  # [C,H,W]\n            img = img.repeat(3,1,1)\n\n        label = self.labels[idx]\n        return img, label\n\n# 2️⃣ Collect image paths & labels\nbase_path = \"/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT\"\nclasses = [\"benign\", \"malignant\", \"normal\"]\nimg_paths, labels = [], []\n\nfor i, cls in enumerate(classes):\n    cls_folder = os.path.join(base_path, cls)\n    for f in os.listdir(cls_folder):\n        if f.endswith(\".png\") or f.endswith(\".jpg\"):\n            img_paths.append(os.path.join(cls_folder, f))\n            labels.append(i)  # 0=benign, 1=malignant, 2=normal\n\n# 3️⃣ Train/Test Split\ntrain_paths, val_paths, train_labels, val_labels = train_test_split(\n    img_paths, labels, test_size=0.2, random_state=42, stratify=labels\n)\n\n# 4️⃣ Transform for ResNet50\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n])\n\n# 5️⃣ DataLoaders\ntrain_dataset = TumorDataset(train_paths, train_labels, transform=transform)\nval_dataset   = TumorDataset(val_paths, val_labels, transform=transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\nval_loader   = DataLoader(val_dataset, batch_size=16, shuffle=False)\n\nprint(f\"✅ Train samples: {len(train_dataset)}, Validation samples: {len(val_dataset)}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3 — Load Pretrained ResNet50","metadata":{}},{"cell_type":"code","source":"from torchvision.models import resnet50, ResNet50_Weights\n\nweights = ResNet50_Weights.DEFAULT  # most up-to-date pretrained weights\nmodel = resnet50(weights=weights)\n\n# Replace the final layer for 3-class classification\nin_features = model.fc.in_features\nmodel.fc = nn.Linear(in_features, 3)\nmodel = model.to(device)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n\n# 2️ Load Pretrained ResNet50\n\nnum_classes = 3  # benign, malignant, normal\nmodel = models.resnet50(pretrained=True)\n\n# Replace the final fully connected layer\nin_features = model.fc.in_features\nmodel.fc = nn.Linear(in_features, num_classes)\nmodel = model.to(device)\n\n\n# 3️ Loss & Optimizer\n\ncriterion = nn.CrossEntropyLoss()  # suitable for multi-class\noptimizer = optim.Adam(model.parameters(), lr=1e-4)\n\nprint(f\" ResNet50 ready for {num_classes}-class classification on device: {device}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm import tqdm\n\n\n# Training Setup\n\nnum_epochs = 10\nbest_val_acc = 0.0\ntrain_losses, val_losses = [], []\ntrain_accs, val_accs = [], []\n\nfor epoch in range(num_epochs):\n    \n    # Training\n  \n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    for imgs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n        imgs, labels = imgs.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(imgs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item() * imgs.size(0)\n        _, predicted = torch.max(outputs, 1)\n        correct += (predicted == labels).sum().item()\n        total += labels.size(0)\n\n    epoch_loss = running_loss / total\n    epoch_acc = correct / total\n    train_losses.append(epoch_loss)\n    train_accs.append(epoch_acc)\n\n    # Validation\n   \n    model.eval()\n    val_loss = 0.0\n    val_correct = 0\n    val_total = 0\n    all_labels, all_preds = [], []\n\n    with torch.no_grad():\n        for imgs, labels in val_loader:\n            imgs, labels = imgs.to(device), labels.to(device)\n            outputs = model(imgs)\n            loss = criterion(outputs, labels)\n\n            val_loss += loss.item() * imgs.size(0)\n            _, predicted = torch.max(outputs, 1)\n            val_correct += (predicted == labels).sum().item()\n            val_total += labels.size(0)\n\n            # Store labels & predictions for confusion matrix\n            all_labels.extend(labels.cpu().numpy())\n            all_preds.extend(predicted.cpu().numpy())\n\n    val_epoch_loss = val_loss / val_total\n    val_epoch_acc = val_correct / val_total\n    val_losses.append(val_epoch_loss)\n    val_accs.append(val_epoch_acc)\n\n    print(f\"Epoch {epoch+1}: Train Loss={epoch_loss:.4f}, Train Acc={epoch_acc:.4f} | \"\n          f\"Val Loss={val_epoch_loss:.4f}, Val Acc={val_epoch_acc:.4f}\")\n\n    # ------------------------\n    # Save Best Model\n    # ------------------------\n    if val_epoch_acc > best_val_acc:\n        best_val_acc = val_epoch_acc\n        torch.save(model.state_dict(), \"best_resnet50.pth\")\n        print(\"✅ Saved best model\")\n\nprint(f\"Training complete. Best validation accuracy: {best_val_acc:.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(12,5))\n\n\n# Loss Curve\n\nplt.subplot(1,2,1)\nplt.plot(train_losses, label='Train Loss', marker='o')\nplt.plot(val_losses, label='Validation Loss', marker='o')\nplt.title(\"Training & Validation Loss (3-Class)\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.grid(True)\n\n\n# Accuracy Curve\n\nplt.subplot(1,2,2)\nplt.plot(train_accs, label='Train Accuracy', marker='o')\nplt.plot(val_accs, label='Validation Accuracy', marker='o')\nplt.title(\"Training & Validation Accuracy (3-Class)\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.grid(True)\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6 — Confusion Matrix","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\n\n# ------------------------\n# Confusion Matrix\n# ------------------------\ncm = confusion_matrix(all_labels, all_preds)\ndisp = ConfusionMatrixDisplay(cm, display_labels=[\"Benign\", \"Malignant\", \"Normal\"])\ndisp.plot(cmap=plt.cm.Blues, values_format='d')  # integer values\nplt.title(\"Confusion Matrix (3-Class)\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport torch\nimport numpy as np\n\n# ------------------------\n# 1️⃣ Visualization Function\n# ------------------------\ndef visualize_classification(images, labels_true, labels_pred, class_names):\n    \"\"\"\n    images: list of tumor patches (224x224x3 or tensors)\n    labels_true: true class indices\n    labels_pred: predicted class indices\n    class_names: list of class names, e.g., ['Normal','Benign','Malignant']\n    \"\"\"\n    plt.figure(figsize=(12,6))\n    \n    for i in range(min(9, len(images))):\n        plt.subplot(3,3,i+1)\n        img = images[i]\n        \n        # Convert tensor to numpy if needed\n        if torch.is_tensor(img):\n            img = img.permute(1,2,0).cpu().numpy()  # C,H,W -> H,W,C\n            img = img * np.array([0.229,0.224,0.225]) + np.array([0.485,0.456,0.406])  # unnormalize\n            img = np.clip(img, 0, 1)\n        \n        plt.imshow(img)\n        plt.title(f\"True: {class_names[labels_true[i]]}\\nPred: {class_names[labels_pred[i]]}\")\n        plt.axis('off')\n    \n    plt.tight_layout()\n    plt.show()\n\n# ------------------------\n# 2️⃣ Prepare validation labels\n# ------------------------\nval_labels = []\nfor path in val_paths:  # val_paths from your DataLoader split\n    if \"benign\" in path.lower():\n        val_labels.append(1)\n    elif \"malignant\" in path.lower():\n        val_labels.append(2)\n    else:  # normal\n        val_labels.append(0)\n\n# ------------------------\n# 3️⃣ Run model on validation set\n# ------------------------\n# Ensure model is defined and on correct device\nresnet = model.to(device)\nresnet.eval()\n\nlabels_pred = []\nwith torch.no_grad():\n    for imgs, _ in val_loader:\n        imgs = imgs.to(device)\n        outputs = resnet(imgs)\n        preds = torch.argmax(outputs, dim=1)\n        labels_pred.extend(preds.cpu().numpy())\n\n# ------------------------\n# 4️⃣ Extract images from dataset (unnormalized for plotting)\n# ------------------------\nval_imgs_for_plot = []\nfor img, _ in val_loader.dataset:\n    val_imgs_for_plot.append(img)\n\n# ------------------------\n# 5️⃣ Visualize predictions\n# ------------------------\nclass_names = ['Normal','Benign','Malignant']\nvisualize_classification(val_imgs_for_plot, val_labels, labels_pred, class_names)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}